{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae4004e7-d796-4b64-ae0a-a7b714c76563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset shape: (649, 5)\n",
      "\n",
      "Columns and dtypes:\n",
      "Company           object\n",
      "Company Score    float64\n",
      "Job Title         object\n",
      "Location          object\n",
      "Salary            object\n",
      "dtype: object\n",
      "\n",
      "Missing values per column:\n",
      "Company            1\n",
      "Company Score     98\n",
      "Job Title          0\n",
      "Location           7\n",
      "Salary           146\n",
      "dtype: int64\n",
      "\n",
      "Dropped 0 exact duplicate rows.\n",
      "\n",
      "Salary annual est IQR bounds: lower=-7750.00, upper=123850.00\n",
      "\n",
      "Saved cleaned dataset to: \\mnt\\data\\cleaned_data_salaries.csv\n",
      "Saved: C:\\Users\\Abdullah Umer\\Desktop\\Internee.pk Internship\\Task 5\\visualizations\\01_top_companies.png\n",
      "Saved: C:\\Users\\Abdullah Umer\\Desktop\\Internee.pk Internship\\Task 5\\visualizations\\02_mean_salary_by_title.png\n",
      "Saved: C:\\Users\\Abdullah Umer\\Desktop\\Internee.pk Internship\\Task 5\\visualizations\\03_salary_distribution.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdullah Umer\\AppData\\Local\\Temp\\ipykernel_12888\\2352875795.py:293: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot(data_to_plot, labels=top6, patch_artist=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\Abdullah Umer\\Desktop\\Internee.pk Internship\\Task 5\\visualizations\\04_boxplot_salary_by_company.png\n",
      "Saved: C:\\Users\\Abdullah Umer\\Desktop\\Internee.pk Internship\\Task 5\\visualizations\\05_score_vs_salary.png\n",
      "Saved: C:\\Users\\Abdullah Umer\\Desktop\\Internee.pk Internship\\Task 5\\visualizations\\06_top_locations_pie.png\n",
      "Saved: C:\\Users\\Abdullah Umer\\Desktop\\Internee.pk Internship\\Task 5\\visualizations\\07_missingness_map.png\n",
      "Saved: C:\\Users\\Abdullah Umer\\Desktop\\Internee.pk Internship\\Task 5\\visualizations\\08_salary_unit_counts.png\n",
      "\n",
      "All visualizations saved to: C:\\Users\\Abdullah Umer\\Desktop\\Internee.pk Internship\\Task 5\\visualizations\n",
      "\n",
      "Cleaning summary:\n",
      "initial_rows : 649\n",
      "final_rows : 649\n",
      "missing_before : {'Company': np.int64(0), 'Company Score': np.int64(0), 'Salary': np.int64(146)}\n",
      "missing_after : {'Company': 0, 'Company_clean': 0, 'Company Score': 0, 'Job Title': 0, 'Job Title_clean': 0, 'Location': 0, 'Loc_City': 7, 'Loc_State': 99, 'Salary': 146, 'Salary_min_raw': 146, 'Salary_max_raw': 146, 'Salary_unit': 146, 'Salary_avg_raw': 146, 'Salary_annual_est': 148, 'Salary_annual_capped': 148}\n",
      "salary_parsed_count : 501\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "   Data Cleaning and Processing \"\"\"\n",
    "\n",
    "import re\n",
    "import math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ---------- Utilities ----------\n",
    "DATA_PATH = Path(\"C:/Users/Abdullah Umer/Desktop/Internee.pk Internship/Task 5/Data_Salaries.csv\")\n",
    "OUT_CSV = Path(\"/mnt/data/cleaned_data_salaries.csv\")\n",
    "OUT_DIR = DATA_PATH.parent / \"visualizations\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def parse_salary_text(s):\n",
    "    \"\"\"\n",
    "    Parse a salary text string and return (min_val, max_val, unit, note)\n",
    "    - min_val/max_val numeric in original unit (e.g., hourly or annual)\n",
    "    - unit: 'hour', 'year', or None\n",
    "    Examples it can handle:\n",
    "      \"$20.00 - $30.00 Per Hour (Employer est.)\"\n",
    "      \"$77K - $130K (Glassdoor est.)\"\n",
    "      \"$100,000\"\n",
    "      \"Employer Provided Salary:$40,000 - $60,000\"\n",
    "    \"\"\"\n",
    "    if pd.isna(s):\n",
    "        return (np.nan, np.nan, None, None)\n",
    "    txt = str(s).replace('\\u00a0', ' ')  # clean non-breaking space\n",
    "    txt = txt.replace(',', '')  # remove thousands separator\n",
    "    txt_low = txt.lower()\n",
    "    \n",
    "    # detect unit\n",
    "    unit = None\n",
    "    if \"per hour\" in txt_low or \"/hour\" in txt_low or \"hour\" in txt_low and \"per\" in txt_low:\n",
    "        unit = 'hour'\n",
    "    if \"per year\" in txt_low or \"per annum\" in txt_low or \"year\" in txt_low or \"yr\" in txt_low or \"annual\" in txt_low or \"k)\" in txt_low:\n",
    "        # note: don't override 'hour' detection if both words present; prefer hour when \"per hour\" matched explicitly\n",
    "        if unit is None:\n",
    "            unit = 'year'\n",
    "    \n",
    "    # find all numeric tokens like 21.50, 130K, 100000\n",
    "    # extract tokens with optional K or M\n",
    "    tokens = re.findall(r'\\$?\\s*([0-9]+(?:\\.[0-9]+)?)([kKmM]?)', txt)\n",
    "    nums = []\n",
    "    for num, suffix in tokens:\n",
    "        try:\n",
    "            v = float(num)\n",
    "            if suffix.lower() == 'k':\n",
    "                v = v * 1000.0\n",
    "            if suffix.lower() == 'm':\n",
    "                v = v * 1_000_000.0\n",
    "            nums.append(v)\n",
    "        except:\n",
    "            continue\n",
    "    # If tokens found, pick min and max\n",
    "    if len(nums) == 0:\n",
    "        # try extracting single number patterns with commas removed\n",
    "        single = re.findall(r'([0-9]{3,})', txt)\n",
    "        if single:\n",
    "            try:\n",
    "                v = float(single[0])\n",
    "                nums = [v]\n",
    "            except:\n",
    "                pass\n",
    "    if len(nums) == 1:\n",
    "        return (nums[0], nums[0], unit, txt)\n",
    "    elif len(nums) >= 2:\n",
    "        return (min(nums), max(nums), unit, txt)\n",
    "    else:\n",
    "        return (np.nan, np.nan, None, txt)\n",
    "\n",
    "def convert_to_annual(min_val, max_val, unit):\n",
    "    \n",
    "\n",
    "    if math.isnan(min_val) and math.isnan(max_val):\n",
    "        return np.nan\n",
    "    vals = []\n",
    "    if not math.isnan(min_val):\n",
    "        vals.append(min_val)\n",
    "    if not math.isnan(max_val):\n",
    "        vals.append(max_val)\n",
    "    mean_val = float(np.mean(vals))\n",
    "    if unit == 'hour':\n",
    "        return mean_val * 2080.0\n",
    "    elif unit == 'year':\n",
    "        return mean_val\n",
    "    else:\n",
    "        # guess: if value seems small (<5000) treat as hourly; if >5000 treat as annual\n",
    "        if mean_val > 0 and mean_val < 5000:\n",
    "            return mean_val * 2080.0\n",
    "        elif mean_val >= 5000:\n",
    "            return mean_val\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "\n",
    "# ---------- Load ----------\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Loaded dataset shape:\", df.shape)\n",
    "\n",
    "\n",
    "# ---------- Initial inspection ----------\n",
    "print(\"\\nColumns and dtypes:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "\n",
    "# ---------- Basic cleaning ----------\n",
    "# Trim whitespace in string columns\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df[col] = df[col].astype(str).str.strip().replace({'nan': None})\n",
    "\n",
    "\n",
    "# Standardize Company Score: ensure numeric\n",
    "if 'Company Score' in df.columns:\n",
    "    df['Company Score'] = pd.to_numeric(df['Company Score'], errors='coerce')\n",
    "\n",
    "\n",
    "# Handle missing Company names: fill with 'Unknown Company'\n",
    "df['Company'] = df['Company'].fillna('Unknown Company')\n",
    "\n",
    "\n",
    "# Handle Location missing\n",
    "df['Location'] = df['Location'].replace({'None': None})\n",
    "df['Location'] = df['Location'].fillna('Not Specified')\n",
    "\n",
    "\n",
    "# Drop exact duplicates (if any)\n",
    "before_dups = df.shape[0]\n",
    "df.drop_duplicates(inplace=True)\n",
    "after_dups = df.shape[0]\n",
    "print(f\"\\nDropped {before_dups - after_dups} exact duplicate rows.\")\n",
    "\n",
    "\n",
    "# ---------- Salary parsing ----------\n",
    "salary_parsed = df['Salary'].apply(parse_salary_text)\n",
    "df[['Salary_min_raw', 'Salary_max_raw', 'Salary_unit_raw', 'Salary_note']] = pd.DataFrame(salary_parsed.tolist(), index=df.index)\n",
    "\n",
    "\n",
    "# Convert raw parsed numbers to floats; if blank string -> NaN\n",
    "df['Salary_min_raw'] = pd.to_numeric(df['Salary_min_raw'], errors='coerce')\n",
    "df['Salary_max_raw'] = pd.to_numeric(df['Salary_max_raw'], errors='coerce')\n",
    "\n",
    "\n",
    "# Infer unit if missing using heuristics on the text\n",
    "df['Salary_unit'] = df['Salary_unit_raw'].copy()\n",
    "# if unit missing and values < 5000 assume hourly else annual\n",
    "mask_no_unit = df['Salary_unit'].isna() & df['Salary_min_raw'].notna()\n",
    "df.loc[mask_no_unit, 'Salary_unit'] = np.where(df.loc[mask_no_unit, 'Salary_min_raw'] < 5000, 'hour', 'year')\n",
    "\n",
    "\n",
    "# Create Avg Salary in original unit\n",
    "df['Salary_avg_raw'] = df[['Salary_min_raw', 'Salary_max_raw']].mean(axis=1)\n",
    "\n",
    "\n",
    "# Create annual salary estimate\n",
    "df['Salary_annual_est'] = df.apply(lambda r: convert_to_annual(r['Salary_min_raw'] if not pd.isna(r['Salary_min_raw']) else np.nan,\n",
    "                                                              r['Salary_max_raw'] if not pd.isna(r['Salary_max_raw']) else np.nan,\n",
    "                                                              r['Salary_unit']), axis=1)\n",
    "\n",
    "\n",
    "# Clean some obvious anomalies: if Salary_annual_est extremely large (>5 million) set to NaN\n",
    "df.loc[df['Salary_annual_est'] > 5_000_000, 'Salary_annual_est'] = np.nan\n",
    "\n",
    "# ---------- Company Score missing handling ----------\n",
    "if 'Company Score' in df.columns:\n",
    "    median_score = df['Company Score'].median(skipna=True)\n",
    "    df['Company Score'] = df['Company Score'].fillna(median_score)\n",
    "\n",
    "# ---------- Job Title cleaning ----------\n",
    "df['Job Title'] = df['Job Title'].astype(str).str.strip().replace({'nan': 'Unknown'})\n",
    "# normalize case\n",
    "df['Job Title_clean'] = df['Job Title'].str.title()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------- Location splitting ----------\n",
    "# If location contains comma (City, ST) try splitting\n",
    "def split_location(loc):\n",
    "    if pd.isna(loc) or loc == 'Not Specified':\n",
    "        return (None, None, loc)\n",
    "    loc = loc.strip()\n",
    "    # common format: \"City, ST\" or \"City, State\"\n",
    "    if ',' in loc:\n",
    "        parts = [p.strip() for p in loc.split(',') if p.strip()!='']\n",
    "        if len(parts) >= 2:\n",
    "            city = parts[0]\n",
    "            state = parts[1]\n",
    "            return (city, state, loc)\n",
    "    # common single tokens: \"Remote\", \"United States\"\n",
    "    return (loc, None, loc)\n",
    "\n",
    "loc_split = df['Location'].apply(split_location)\n",
    "df[['Loc_City', 'Loc_State', 'Location_original']] = pd.DataFrame(loc_split.tolist(), index=df.index)\n",
    "\n",
    "# Standardize company names lightly\n",
    "df['Company_clean'] = df['Company'].str.replace(r'\\s+', ' ', regex=True).str.title()\n",
    "\n",
    "# ---------- Outlier handling for Salary_annual_est ----------\n",
    "# We'll identify outliers using IQR and cap them at [Q1-1.5*IQR, Q3+1.5*IQR] for demonstration (winsorization)\n",
    "sal = df['Salary_annual_est']\n",
    "q1 = sal.quantile(0.25)\n",
    "q3 = sal.quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "print(f\"\\nSalary annual est IQR bounds: lower={lower_bound:.2f}, upper={upper_bound:.2f}\")\n",
    "\n",
    "# Create capped salary column\n",
    "df['Salary_annual_capped'] = df['Salary_annual_est'].copy()\n",
    "df.loc[df['Salary_annual_capped'] < lower_bound, 'Salary_annual_capped'] = lower_bound\n",
    "df.loc[df['Salary_annual_capped'] > upper_bound, 'Salary_annual_capped'] = upper_bound\n",
    "\n",
    "\n",
    "\n",
    "# ---------- Final tidy columns & save ----------\n",
    "final_cols = ['Company', 'Company_clean', 'Company Score', 'Job Title', 'Job Title_clean',\n",
    "              'Location', 'Loc_City', 'Loc_State', 'Salary', 'Salary_min_raw', 'Salary_max_raw',\n",
    "              'Salary_unit', 'Salary_avg_raw', 'Salary_annual_est', 'Salary_annual_capped']\n",
    "\n",
    "# ensure all final cols exist\n",
    "for c in final_cols:\n",
    "    if c not in df.columns:\n",
    "        df[c] = None\n",
    "\n",
    "cleaned = df[final_cols].copy()\n",
    "cleaned.to_csv(OUT_CSV, index=False)\n",
    "print(f\"\\nSaved cleaned dataset to: {OUT_CSV}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------- VISUALIZATIONS ----------\n",
    "\n",
    "\n",
    "plt.style.use('default')  # start from default; we'll set background color manually per figure\n",
    "\n",
    "# Helper to save fig with a bright background and friendly dark colors\n",
    "def save_fig(fig, filename, fig_size=(10,6), bgcolor='#ffffff'):\n",
    "    fig.set_facecolor(bgcolor)\n",
    "    # also set axes background\n",
    "    for ax in fig.get_axes():\n",
    "        ax.set_facecolor('#ffffff')  # bright background for axes\n",
    "    path = OUT_DIR / filename\n",
    "    fig.savefig(path, bbox_inches='tight', dpi=150)\n",
    "    print(\"Saved:\", path)\n",
    "\n",
    "# 1) Top 10 companies by count of listings\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "top_comp = cleaned['Company_clean'].value_counts().nlargest(10)\n",
    "bars = ax.barh(top_comp.index[::-1], top_comp.values[::-1], color=['#2E4057', '#3E7CB1', '#5DA5A4', '#F39C12', '#E67E22', '#8E44AD', '#27AE60', '#C0392B', '#D35400', '#1F618D'][0:len(top_comp)])\n",
    "ax.set_title(\"Top 10 Companies (by number of internship listings)\", fontsize=14, weight='bold')\n",
    "ax.set_xlabel(\"Number of Listings\")\n",
    "ax.grid(axis='x', linestyle='--', alpha=0.4)\n",
    "save_fig(fig, \"01_top_companies.png\")\n",
    "\n",
    "plt.close(fig)\n",
    "\n",
    "# 2) Average (mean) annual salary by top 10 job titles (based on counts)\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "top_titles = cleaned['Job Title_clean'].value_counts().nlargest(10).index.tolist()\n",
    "mean_sal_by_title = cleaned.groupby('Job Title_clean')['Salary_annual_est'].mean().loc[top_titles].sort_values()\n",
    "bars = ax.barh(mean_sal_by_title.index[::-1], mean_sal_by_title.values[::-1], color=['#34495E', '#7FB3D5', '#73C6B6', '#F7DC6F', '#F1948A', '#BB8FCE', '#76D7C4', '#F5B041', '#D98880', '#5DADE2'][0:len(mean_sal_by_title)])\n",
    "ax.set_title(\"Mean Estimated Annual Salary by Top Job Titles\", fontsize=14, weight='bold')\n",
    "ax.set_xlabel(\"Mean Annual Salary (USD)\")\n",
    "ax.grid(axis='x', linestyle='--', alpha=0.4)\n",
    "save_fig(fig, \"02_mean_salary_by_title.png\")\n",
    "plt.close(fig)\n",
    "\n",
    "# 3) Distribution histogram of estimated annual salary (capped)\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.hist(cleaned['Salary_annual_capped'].dropna(), bins=30, edgecolor='black', color='#2C3E50', alpha=0.9)\n",
    "ax.set_title(\"Distribution of Estimated Annual Salary (winsorized)\", fontsize=14, weight='bold')\n",
    "ax.set_xlabel(\"Annual Salary (USD)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.4)\n",
    "save_fig(fig, \"03_salary_distribution.png\")\n",
    "plt.close(fig)\n",
    "\n",
    "# 4) Boxplot: Salary by company (top 6 companies)\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "top6 = cleaned['Company_clean'].value_counts().nlargest(6).index.tolist()\n",
    "data_to_plot = [cleaned.loc[cleaned['Company_clean']==c, 'Salary_annual_capped'].dropna() for c in top6]\n",
    "ax.boxplot(data_to_plot, labels=top6, patch_artist=True,\n",
    "           boxprops=dict(facecolor='#AED6F1'), medianprops=dict(color='#1B4F72'))\n",
    "ax.set_title(\"Salary Distribution for Top 6 Companies (winsorized)\", fontsize=14, weight='bold')\n",
    "ax.set_ylabel(\"Annual Salary (USD)\")\n",
    "ax.tick_params(axis='x', rotation=30)\n",
    "save_fig(fig, \"04_boxplot_salary_by_company.png\")\n",
    "plt.close(fig)\n",
    "\n",
    "# 5) Scatter: Company Score vs Avg Estimated Annual Salary\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "x = cleaned['Company Score']\n",
    "y = cleaned['Salary_annual_est']\n",
    "mask = (~x.isna()) & (~y.isna())\n",
    "ax.scatter(x[mask], y[mask], s=40, alpha=0.8, c='#2E86C1', edgecolors='#154360')\n",
    "ax.set_title(\"Company Score vs Estimated Annual Salary\", fontsize=14, weight='bold')\n",
    "ax.set_xlabel(\"Company Score\")\n",
    "ax.set_ylabel(\"Estimated Annual Salary (USD)\")\n",
    "ax.grid(True, linestyle='--', alpha=0.3)\n",
    "save_fig(fig, \"05_score_vs_salary.png\")\n",
    "plt.close(fig)\n",
    "\n",
    "# 6) Pie chart: Top locations (by listing count)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111)\n",
    "top_loc = cleaned['Location'].value_counts().nlargest(6)\n",
    "colors = ['#1F618D', '#2E4053', '#27AE60', '#F39C12', '#AF7AC5', '#F1948A'][0:len(top_loc)]\n",
    "ax.pie(top_loc.values, labels=top_loc.index, autopct='%1.1f%%', startangle=140, colors=colors, wedgeprops=dict(edgecolor='white'))\n",
    "ax.set_title(\"Top Locations (by number of listings)\", fontsize=14, weight='bold')\n",
    "save_fig(fig, \"06_top_locations_pie.png\")\n",
    "plt.close(fig)\n",
    "\n",
    "# 7) Heatmap-like visualization of missingness (basic; without seaborn)\n",
    "fig = plt.figure(figsize=(10,4))\n",
    "ax = fig.add_subplot(111)\n",
    "missing_matrix = cleaned.isnull().astype(int).T  # columns as rows for display\n",
    "cax = ax.imshow(missing_matrix, aspect='auto', interpolation='nearest', cmap='Greys', vmin=0, vmax=1)\n",
    "ax.set_yticks(range(len(missing_matrix.index)))\n",
    "ax.set_yticklabels(missing_matrix.index)\n",
    "ax.set_xticks([])\n",
    "ax.set_title(\"Missingness Map (1 = missing, 0 = present)\", fontsize=12, weight='bold')\n",
    "save_fig(fig, \"07_missingness_map.png\")\n",
    "plt.close(fig)\n",
    "\n",
    "# 8) Bar: Count by salary unit (hour/year/unknown inferred)\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "unit_counts = cleaned['Salary_unit'].fillna('unknown').value_counts()\n",
    "bars = ax.bar(unit_counts.index, unit_counts.values, color=['#1B4F72', '#117A65', '#7D3C98'][0:len(unit_counts)])\n",
    "ax.set_title(\"Counts by Salary Unit (hour / year / unknown-inferred)\", fontsize=14, weight='bold')\n",
    "ax.set_xlabel(\"Salary Unit\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.4)\n",
    "save_fig(fig, \"08_salary_unit_counts.png\")\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"\\nAll visualizations saved to:\", OUT_DIR)\n",
    "\n",
    "\n",
    "# Provide a small summary of cleaning actions\n",
    "summary = {\n",
    "    \"initial_rows\": df.shape[0],\n",
    "    \"final_rows\": cleaned.shape[0],\n",
    "    \"missing_before\": {\"Company\": df['Company'].isnull().sum(), \"Company Score\": df['Company Score'].isnull().sum() if 'Company Score' in df.columns else None, \"Salary\": df['Salary'].isnull().sum()},\n",
    "    \"missing_after\": cleaned.isnull().sum().to_dict(),\n",
    "    \"salary_parsed_count\": cleaned['Salary_annual_est'].notnull().sum()\n",
    "}\n",
    "print(\"\\nCleaning summary:\")\n",
    "for k,v in summary.items():\n",
    "    print(k, \":\", v)\n",
    "\n",
    "\n",
    "\n",
    "# End of script. The cleaned CSV is saved and 8 PNG visualizations are saved.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5229f15d-59e0-443c-ac48-f5a594776e69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
